{"cells":[{"cell_type":"code","execution_count":null,"id":"23900f72","metadata":{"id":"23900f72"},"outputs":[],"source":["#video prediction"]},{"cell_type":"code","source":["import cv2\n","import os\n","\n","def extract_frames(video_path, frame_count=5, resize_dims=(128, 128)):\n","    # Extract video file name without extension\n","    video_name = os.path.splitext(os.path.basename(video_path))[0]\n","\n","    # Open the video file\n","    cap = cv2.VideoCapture(video_path)\n","    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","    frames_to_capture = sorted(set(int(total_frames * i / frame_count) for i in range(frame_count)))\n","\n","    extracted_frames = []\n","    frame_idx = 0\n","    saved_frame_count = 0\n","    while True:\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","        if frame_idx in frames_to_capture:\n","            saved_frame_count += 1\n","            # Resize frame\n","            resized_frame = cv2.resize(frame, resize_dims)\n","            # Save frame as image, named according to the video and frame number\n","            frame_filename = f'{video_name}_frame{saved_frame_count}.jpg'\n","            cv2.imwrite(frame_filename, resized_frame)\n","            extracted_frames.append(frame_filename)\n","        frame_idx += 1\n","        if saved_frame_count == frame_count:\n","            break\n","\n","    cap.release()\n","    return extracted_frames\n","\n","# Example usage:\n","video_path = 'video.mp4'  # Replace with your actual video file path\n","frames = extract_frames(video_path)"],"metadata":{"id":"Hnx7kKL2tq0Z"},"id":"Hnx7kKL2tq0Z","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"a7b729af","metadata":{"scrolled":true,"id":"a7b729af","outputId":"07668d69-d5ae-4806-b29b-5ca95b2be89b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713235481230,"user_tz":420,"elapsed":2183,"user":{"displayName":"Brendan Bickford","userId":"04312162511110788568"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","0: 128x128 surprise 0.64, embarrassment 0.22, confusion 0.13, frustration 0.02, 1: 128x128 surprise 0.47, embarrassment 0.38, confusion 0.14, frustration 0.01, 2: 128x128 surprise 0.58, embarrassment 0.24, confusion 0.17, frustration 0.02, 3: 128x128 surprise 0.38, embarrassment 0.33, confusion 0.28, frustration 0.01, 4: 128x128 surprise 0.53, confusion 0.26, embarrassment 0.20, frustration 0.01, 251.4ms\n","Speed: 0.7ms preprocess, 50.3ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n","Results saved to \u001b[1mpredictions/predict\u001b[0m\n","5 labels saved to predictions/predict/labels\n"]}],"source":["#!pip install ultralytics==8.0.230\n","from ultralytics import YOLO\n","\n","# Load the best version of the model\n","# This must be the location to the model\n","model = YOLO('Trained_Model.pt')\n","\n","\n","# Select image or list of images to predict\n","results = model(frames, save=True, save_txt=True, project=\"predictions\")"]},{"cell_type":"code","execution_count":null,"id":"ee367b7a","metadata":{"id":"ee367b7a"},"outputs":[],"source":["#audio prediction"]},{"cell_type":"code","execution_count":null,"id":"f2c1e6ee","metadata":{"id":"f2c1e6ee"},"outputs":[],"source":["import librosa\n","from keras.models import load_model\n","from moviepy.editor import VideoFileClip"]},{"cell_type":"code","execution_count":null,"id":"72c55a93","metadata":{"id":"72c55a93"},"outputs":[],"source":["model_path = 'my_lstm_model.h5'\n","from keras.models import load_model\n","model = load_model(model_path)"]},{"cell_type":"code","execution_count":null,"id":"a733fb05","metadata":{"id":"a733fb05","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713235481789,"user_tz":420,"elapsed":347,"user":{"displayName":"Brendan Bickford","userId":"04312162511110788568"}},"outputId":"536d68e6-38b1-48cb-d3ed-c60bbed47a74"},"outputs":[{"output_type":"stream","name":"stdout","text":["MoviePy - Writing audio in extracted_audio.wav\n"]},{"output_type":"stream","name":"stderr","text":["                                                        "]},{"output_type":"stream","name":"stdout","text":["MoviePy - Done.\n"]},{"output_type":"stream","name":"stderr","text":["\r"]}],"source":["from moviepy.editor import VideoFileClip\n","\n","# Path to your video file\n","#video_path = 'Confusion-Test.mp4'\n","\n","# Create a VideoFileClip instance\n","video_clip = VideoFileClip(video_path)\n","\n","# Set the path for the extracted audio file\n","audio_path = 'extracted_audio.wav'\n","\n","# Extract the audio from the video clip and save it to the audio_path\n","video_clip.audio.write_audiofile(audio_path)\n","\n","# The audio is now extracted and saved as 'extracted_audio.wav'\n"]},{"cell_type":"code","execution_count":null,"id":"dd32c673","metadata":{"id":"dd32c673","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713235482320,"user_tz":420,"elapsed":534,"user":{"displayName":"Brendan Bickford","userId":"04312162511110788568"}},"outputId":"6a9ae810-9e20-4008-d6d1-d6cbad0d81fd"},"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 474ms/step\n"]}],"source":["import librosa\n","import numpy as np\n","\n","data, sample_rate = librosa.load(audio_path, sr=None)\n","mfccs = librosa.feature.mfcc(y=data, sr=sample_rate, n_mfcc=40)\n","mfccs = np.mean(mfccs.T, axis=0)\n","mfccs = np.expand_dims(mfccs, axis=0)\n","mfccs = np.expand_dims(mfccs, axis=2)\n","prediction = model.predict(mfccs)\n","predicted_class = np.argmax(prediction, axis=1)\n","prediction_score = np.max(prediction, axis=1)[0]  # Max score for the predicted class\n","emotion_labels = ['frustration', 'confusion', 'embarrassment', 'surprise']  # Adjusted labels\n","predicted_emotion = emotion_labels[predicted_class[0]]\n","\n","# Specify the full path where the audio.txt file should be saved\n","file_path = 'predictions/predict/labels/audio.txt'\n","\n","# Writing the score and emotion to a txt file in the requested format\n","with open(file_path, 'w') as file:\n","    file.write(f'{prediction_score:.2f} {predicted_emotion}')"]},{"cell_type":"code","execution_count":null,"id":"430835ed","metadata":{"id":"430835ed"},"outputs":[],"source":["#fusion"]},{"cell_type":"code","execution_count":null,"id":"affb0a84","metadata":{"id":"affb0a84","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713235482321,"user_tz":420,"elapsed":9,"user":{"displayName":"Brendan Bickford","userId":"04312162511110788568"}},"outputId":"c796aee7-5fe8-4a99-af9f-ed6c51aa7614"},"outputs":[{"output_type":"stream","name":"stdout","text":["Emoji: (Surprise score: 0.64): üò≥\n"]}],"source":["import os\n","\n","emotion_to_emojis = {\n","    'confusion': ('ü§®', 'ü§î', 'üòµ‚Äçüí´'),\n","    'embarrassment': ('üò¨', 'üò•', 'üôà'),\n","    'frustration': ('üò£', 'üòê', 'üò§'),\n","    'surprise': ('üò≤', 'üò≥', 'üò±')\n","}\n","\n","def get_emoji(score, emojis):\n","    if 0.0 <= score <= 0.33:\n","        return emojis[0]\n","    elif 0.34 <= score <= 0.66:\n","        return emojis[1]\n","    elif 0.67 <= score <= 1.0:\n","        return emojis[2]\n","    return None\n","\n","# Folder Path\n","folder_path = 'predictions/predict/labels/'\n","\n","# Initialize variables to store the maximum score and corresponding emotion\n","max_score = -1\n","max_emotion = None\n","selected_emoji = None\n","\n","# Iterate over each file in the directory\n","for filename in os.listdir(folder_path):\n","    if filename.endswith(\".txt\"):\n","        file_path = os.path.join(folder_path, filename)\n","        with open(file_path, 'r') as file:\n","            lines = file.readlines()\n","\n","        for line in lines:\n","            parts = line.split()\n","            score = float(parts[0])\n","            emotion = parts[1].lower()\n","\n","            if score > max_score:\n","                max_score = score\n","                max_emotion = emotion\n","                selected_emoji = get_emoji(score, emotion_to_emojis[emotion]) if emotion in emotion_to_emojis else None\n","\n","if selected_emoji:\n","    print(f\"Emoji: ({max_emotion.capitalize()} score: {max_score}): {selected_emoji}\")\n","else:\n","    print(\"No valid emotion found.\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}